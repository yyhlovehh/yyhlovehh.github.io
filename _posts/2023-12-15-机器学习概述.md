# 机器学习概述

## 1.机器学习定义

![2_1](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312151742485.png)

![2_2](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312151743988.png)

![2_3](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312151744668.png)

与拟合的区别：要在整个数据上的预测误差都小。

## 2.机器学习类型

![2_4](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312151755269.png)

回归问题：输出为连续值。

分类：输出y为离散值。

聚类：训练样本没有输出的类别（标签），**是一类无监督问题，训练样本只有x没有y。**

强化学习：例如下围棋。根据最终的输赢让程序自我调整，通过与环境进行交互来学习，本质是不断试错，尝试各种可能。

![2_5](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312151803798.png)

![2_6](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312152331831.png)

![2_7](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312152331013.png)

## 3.机器学习的要素

![2_8](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312152343844.png)

![2_9](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312152343939.png)

![2_10](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161354620.png)

![2_11](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161354903.png)

损失函数：

![2_12](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161357486.png)

![2_13](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161358605.png)

![2_14](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161400938.png)

![2_15](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161401105.png)

![2_16](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161403477.png)



希望为自适应学习。

![2_19](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161410634.png)

![2_18](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161407280.png)

## 4.泛化与正则化

![2_20](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161412695.png)

机器学习关注的是期望的曲线，在验证集的损失函数也很小；而优化只关注训练集。

如果经验风险低，期望风险高，就会发生过拟合。

![2_21](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161416278.png)

![2_22](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161417749.png)

![2_23](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161418754.png)

![2_24](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312161419638.png)



提前停止用的很多。

## 5.线性回归

![2_25](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171417718.png)

回归问题：

y一般为标量，且连续；x可以为标量，也可以为向量。

![2_26](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171420008.png)

**增广矩阵消除偏置。**

![2_27](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171425322.png)

![2_31](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171438757.png)

![2_30](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171433983.png)

怎么求解优化方程？偏导数？

![2_29](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171429111.png)

![2_32](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171441963.png)

## 6.多项式回归

![2_33](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171443961.png)

![2_34](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171445806.png)

![2_35](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171455673.png)

![2_36](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171456639.png)

![2_37](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171459374.png)

![2_38](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171459060.png)

![2_39](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171500741.png)

![2_40](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171501376.png)

## 7.线性回归的概率视角

![2_41](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171509745.png)

假设真实函数为f(x,w),且样本误差服从均值为0，方差的高斯分布，构造函数y,则y也服从高斯分布。

![2_42](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171510144.png)

![2_43](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171514814.png)

![2_44](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171515967.png)

就是最小二乘的解，等价于经验风险估计的解。

![2_45](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171518628.png)

![2_46](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171521703.png)

![2_49](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171528886.png)

![2_50](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171530512.png)

![2_48](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171524759.png)

## 8.模型选择与“偏差-方差”分解

![2_53](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171601637.png)

![2_54](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171602167.png)

![2_55](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171602989.png)

![2_56](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171602348.png)

![2_51](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171547415.png)

![2_52](https://raw.githubusercontent.com/yyhlovehh/yyhlovehh.github.io/master/202312171548881.png)

## 9.常用定理



